{"cells":[{"cell_type":"markdown","metadata":{"id":"sQG9hL8-UQUP"},"source":["# Multi-VAE\n","\n","이번 미션에서는 [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)에서 제안된 Multi-VAE 기반의 협업 필터링을 구현해보도록 하겠습니다. 다양한 Auto-Encoder 기반의 협업필터링이 제안된 이후에, 가장 강력하다고 평가받는 VAE 기반의 협업 필터링을 이해하는 시간을 갖도록 하겠습니다.\n","\n","- 이 미션은 다음 [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다. 바로 코드를 확인해보지 마시고, 최대한 직접 작성을 해보세요!\n","- 이 미션에서 중요한 부분은 모델 부분입니다. 데이터 전처리 부분은 가볍게 훑어 보시고, 모델 부분을 집중해주세요!\n","- 완성을 해야할 부분은 TODO로 표시가 되어있습니다."]},{"cell_type":"markdown","metadata":{"id":"J7CfnRw7U59C"},"source":["## 1. 초기 세팅"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11383,"status":"ok","timestamp":1670464079058,"user":{"displayName":"김강민","userId":"16082862873898795036"},"user_tz":-540},"id":"EWWEf1mPKdnX","outputId":"627a84be-0adc-4cf2-a9de-478c7e81cad1"},"outputs":[],"source":["## 전처리과정에서 pandas의 버전에 다르게 동작하는 경향이 보여, 이 미션에서는 아래 버전으로 사용하도록하겠습니다.\n","# !pip install pandas==1.0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQj6k1mSbxaz"},"outputs":[],"source":["import argparse\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from scipy import sparse\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"j3E2IJSMjO_6"},"source":["### 데이터 다운로드\n","이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요. \n","- 데이터 URL은 변경될 수 있습니다.\n","- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4232,"status":"ok","timestamp":1647318082403,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jJ1hFEoNA7OE","outputId":"b08804c0-9813-4949-f77d-961694e4cc3a"},"outputs":[],"source":["# !wget <대회 데이터 URL>\n","# !tar -xf data.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1647318083899,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"xQ3W0udmbxa3","outputId":"d556fee8-e1e8-4365-9068-551ba45d1aed"},"outputs":[],"source":["## 각종 파라미터 세팅\n","parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n","\n","\n","parser.add_argument('--data', type=str, default='',\n","                    help='Movielens dataset location')\n","\n","parser.add_argument('--lr', type=float, default=1e-4,\n","                    help='initial learning rate')\n","parser.add_argument('--wd', type=float, default=0.00,\n","                    help='weight decay coefficient')\n","parser.add_argument('--batch_size', type=int, default=500,\n","                    help='batch size')\n","parser.add_argument('--epochs', type=int, default=20,\n","                    help='upper epoch limit')\n","parser.add_argument('--total_anneal_steps', type=int, default=200000,\n","                    help='the total number of gradient updates for annealing')\n","parser.add_argument('--anneal_cap', type=float, default=0.2,\n","                    help='largest annealing parameter')\n","parser.add_argument('--seed', type=int, default=1111,\n","                    help='random seed')\n","parser.add_argument('--cuda', action='store_true',\n","                    help='use CUDA')\n","parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n","                    help='report interval')\n","parser.add_argument('--save', type=str, default='model.pt',\n","                    help='path to save the final model')\n","args = parser.parse_args([])\n","\n","# Set the random seed manually for reproductibility.\n","torch.manual_seed(args.seed)\n","\n","#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n","if torch.cuda.is_available():\n","    args.cuda = True\n","\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7o1fvXqFWE_G"},"source":["## 2. 데이터 전처리\n","\n","이 부분에서 진행되는 과정은 저희가 일반적으로 알고있는 MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. 전처리 과정의 다양한 옵션들을 구성하기 위해 약간 복잡하게 되었지만, \n","결과적으로는, 유저들의 특정한 아이템들을 따로 분리를 해서, 그 분리된 값을 모델이 예측할 수 있냐를 확인하기 위한 전처리 과정이라고 보시면 되겠습니다.\n","실제로 나오는 데이터셋을 확인하면 더욱 이해가 빠를것입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgvNoy1Ybxa6"},"outputs":[],"source":["import os\n","import pandas as pd\n","from scipy import sparse\n","import numpy as np\n","\n","# 데이터 tp 의 항목 id 가 몇개인지 세주는 함수\n","def get_count(tp, id):\n","    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n","    count = playcount_groupbyid.size()\n","\n","    return count\n","\n","# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n","# 데이터만을 추출할 때 사용하는 함수입니다.\n","# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n","\n","# 최소 유저, 아이템 이상의 데이터들만 뽑아서 데이터 변환. count 도 포함해서 return\n","def filter_triplets(tp, min_uc=5, min_sc=0):\n","    if min_sc > 0:\n","        itemcount = get_count(tp, 'item')\n","        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n","\n","    if min_uc > 0:\n","        usercount = get_count(tp, 'user')\n","        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n","\n","    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n","    return tp, usercount, itemcount\n","\n","#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n","#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n","#확인하기 위함입니다.\n","def split_train_test_proportion(data, test_prop=0.2):\n","    #데이터를 유저별로 묶고\n","    data_grouped_by_user = data.groupby('user')\n","    tr_list, te_list = list(), list()\n","\n","    np.random.seed(98765)\n","    \n","    for _, group in data_grouped_by_user:\n","        n_items_u = len(group)\n","        \n","        #평가 5개 이상인 것들은 \n","        if n_items_u >= 5:\n","            # 전체 False 인 numpy 생성\n","            idx = np.zeros(n_items_u, dtype='bool')\n","            #test_prop 비율 만큼 랜덤으로 True 값으로 변경\n","            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n","\n","            tr_list.append(group[np.logical_not(idx)])\n","            te_list.append(group[idx])\n","        \n","        #평가 5개이하 한것들은 train으로\n","        else:\n","            tr_list.append(group)\n","    \n","    data_tr = pd.concat(tr_list)\n","    data_te = pd.concat(te_list)\n","\n","    return data_tr, data_te\n","\n","def numerize(tp, profile2id, show2id):\n","    uid = tp['user'].apply(lambda x: profile2id[x])\n","    sid = tp['item'].apply(lambda x: show2id[x])\n","    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4637,"status":"ok","timestamp":1647318092923,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"fVFoRHrmVQsp","outputId":"bb4178bc-0dcc-454b-eddb-10f83179f778"},"outputs":[],"source":["print(\"Load and Preprocess Movielens dataset\")\n","# Load Data\n","DATA_DIR = args.data\n","raw_data = pd.read_csv(os.path.join(DATA_DIR, 'useritem.csv'), header=0)\n","print(\"원본 데이터\\n\", raw_data)\n","\n","# Filter Data\n","raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=1, min_sc=0)\n","#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n","print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n","\n","print(\"유저별 리뷰수\\n\",user_activity)\n","print(\"아이템별 리뷰수\\n\",item_popularity)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1647318093321,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"7T1dTsWUrffP","outputId":"c3f79dfb-8854-4894-bd36-dc07d5f9ee93"},"outputs":[],"source":["# Shuffle User Indices\n","unique_uid = user_activity.index\n","print(\"(BEFORE) unique_uid:\",unique_uid)\n","np.random.seed(98765)\n","idx_perm = np.random.permutation(unique_uid.size)\n","unique_uid = unique_uid[idx_perm]\n","print(\"(AFTER) unique_uid:\",unique_uid)\n","\n","n_users = unique_uid.size #31360\n","n_heldout_users = 3000\n","\n","\n","# Split Train/Validation/Test User Indices\n","tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n","vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n","te_users = unique_uid[(n_users - n_heldout_users):]\n","sub_users = unique_uid\n","#주의: 데이터의 수가 아닌 사용자의 수입니다!\n","print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n","print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n","print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))\n","print(\"제출 데이터에 사용될 사용자 수:\", len(sub_users))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20754,"status":"ok","timestamp":1647318114955,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"3yBsRCRqtPz6","outputId":"1f8c7e6e-6ff0-42d6-bb9a-367dfc5d16bb"},"outputs":[],"source":["#훈련 데이터에 해당하는 아이템들\n","# Train에는 전체 데이터를 사용합니다.\n","train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n","\n","sub_plays = raw_data.loc[raw_data['user'].isin(sub_users)]\n","\n","#아이템 ID\n","unique_sid = pd.unique(train_plays['item'])\n","unique_sub_sid = pd.unique(sub_plays['item'])\n","\n","id2user = dict((i, pid) for (i, pid) in enumerate(pd.unique(sub_plays['user'])))\n","id2item = dict((i, pid) for (i, pid) in enumerate(pd.unique(sub_plays['item'])))\n","\n","show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n","profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n","\n","sub_show2id = dict((sid, i) for (i, sid) in enumerate(unique_sub_sid))\n","sub_profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n","\n","pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n","\n","if not os.path.exists(pro_dir):\n","    os.makedirs(pro_dir)\n","\n","with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n","    for sid in unique_sid:\n","        f.write('%s\\n' % sid)\n","\n","with open(os.path.join(pro_dir, 'unique_sub_sid.txt'), 'w') as f:\n","    for sid in unique_sub_sid:\n","        f.write('%s\\n' % sid)\n","\n","# Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n","vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n","vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n","vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n","\n","test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n","test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n","test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n","\n","\n","\n","train_data = numerize(train_plays, profile2id, show2id)\n","train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n","\n","sub_data = numerize(sub_plays, sub_profile2id, sub_show2id)\n","sub_data.to_csv(os.path.join(pro_dir, 'sub.csv'), index=False)\n","\n","\n","vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n","vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n","\n","vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n","vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n","\n","test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n","test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n","\n","test_data_te = numerize(test_plays_te, profile2id, show2id)\n","test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n","\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1647318114956,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jkdg2OkjqVUM","outputId":"393ce3ea-8f6a-4681-de4b-4c25eef547db"},"outputs":[],"source":["#데이터 셋 확인\n","print(train_data)\n","print(vad_data_tr)\n","print(vad_data_te)\n","# print(test_data_tr)\n","# print(test_data_te)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","path = os.path.join(f'pro_sg/sub.csv')\n","\n","tp = pd.read_csv(path)\n","n_users = tp['uid'].max() + 1\n","n_items = tp['sid'].max() + 1\n","rows, cols = tp['uid'], tp['sid']\n","#compressed sparse row matrix로 변환하기 (희소행렬을 다른식으로 변환하여 저장하는 방법)\n","data = sparse.csr_matrix((np.ones_like(rows),\n","                            (rows, cols)), dtype='float64',\n","                            shape=(n_users, n_items))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SMiq9leyWWL1"},"source":["## 3. 데이터 로더 설정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxUADr9ibxa8"},"outputs":[],"source":["\n","class DataLoader():\n","    '''\n","    Load Movielens dataset\n","    '''\n","    def __init__(self, path):\n","        \n","        self.pro_dir = os.path.join(path, 'pro_sg')\n","        #error 설정\n","        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n","        # load_n_items 를 통해 이전에 저장해뒀던 아이템의 랜덤 순서 불러옴\n","        self.n_items = self.load_n_items()\n","    \n","    def load_data(self, datatype='train'):\n","        if datatype == 'train':\n","            return self._load_train_data()\n","        elif datatype == 'validation':\n","            return self._load_tr_te_data(datatype)\n","        elif datatype == 'test':\n","            return self._load_tr_te_data(datatype)\n","        elif datatype == 'sub':\n","            return self._load_train_data(datatype)\n","        else:\n","            raise ValueError(\"datatype should be in [train, validation, test, submission]\")\n","    \n","    # self.n_items 에 이전에 저장해뒀던 아이템의 랜덤순서 가져다주는 함수\n","    def load_n_items(self):\n","        unique_sid = list()\n","        with open(os.path.join(self.pro_dir, 'unique_sub_sid.txt'), 'r') as f:\n","            for line in f:\n","                unique_sid.append(line.strip())\n","        n_items = len(unique_sid)\n","        return n_items\n","    \n","    def _load_train_data(self, datatype = 'train'):\n","        path = os.path.join(self.pro_dir, f'{datatype}.csv')\n","        \n","        tp = pd.read_csv(path)\n","        n_users = tp['uid'].max() + 1\n","\n","        rows, cols = tp['uid'], tp['sid']\n","        #compressed sparse row matrix로 변환하기 (희소행렬을 다른식으로 변환하여 저장하는 방법)\n","        data = sparse.csr_matrix((np.ones_like(rows),\n","                                 (rows, cols)), dtype='float64',\n","                                 shape=(n_users, self.n_items))\n","        return data\n","    \n","    def _load_tr_te_data(self, datatype='test'):\n","        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n","        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n","\n","        tp_tr = pd.read_csv(tr_path)\n","        tp_te = pd.read_csv(te_path)\n","\n","        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n","        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n","\n","        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n","        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n","\n","        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n","                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n","                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        return data_tr, data_te"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6FHhwKqXWaUZ"},"source":["## 4. 모델정의\n","\n","VAE 코드 참고: https://atcold.github.io/pytorch-Deep-Learning/ko/week08/08-3/\n","\n","multi-vae 는 multinomial likelihood를 사용하기 때문에 implicit feedback data를 더 잘 설명할 수 있다고 한다.\n","\n","Multi-vae 이론 참고: https://velog.io/@2712qwer/Paper-Code-Review-2018-WWW-Variational-Autoencoders-for-Collaborative-Filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYlGPJTYU0ii"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","\n","\n","#이미 완성된 MultiDAE(denoising auto encoder)의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n","class MultiDAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-DAE.\n","\n","    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiDAE, self).__init__()\n","        #p_dims, q_dims 는 input, output dimension 리스트\n","        #p_dims = [200, 600, 6807]\n","        self.p_dims = p_dims\n","        #q_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        # q_dims 없으면 p_dims 순서 뒤집어서 사용\n","        else:\n","            self.q_dims = p_dims[::-1]\n","        # 항목이 5개가 되게 함\n","        self.dims = self.q_dims + self.p_dims[1:]\n","        # nn.Sequential 과 비슷한함수로, Module 여러개 담아놓는 역할\n","        # nn.Linear(6807, 600), nn.Linear(600,200),nn.Linear(200, 600),nn.Linear(600,6807)\n","        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n","        self.drop = nn.Dropout(dropout)\n","        \n","        self.init_weights()\n","    \n","    def forward(self, input):\n","        #input 정규화 (이유 : 학습 속도 높이고, Local optimum에 빠지게 하지 않기 위해)\n","        #input dropout 으로 몇가닥 끊기(과적합 방지)\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","        #nn.Module에 저장해 뒀던 Linear 함수 적용\n","        for i, layer in enumerate(self.layers):\n","            h = layer(h)\n","            # 마지막 항에서는 tanh로 activation function 적용\n","            if i != len(self.layers) - 1:\n","                h = F.tanh(h)\n","        return h\n","\n","    def init_weights(self):\n","        # 가중치 초기화 하는 함수 \n","        for layer in self.layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            # 가중치 함수 초기화 (평균=0 , 표준편차 = std)\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","def loss_function_dae(recon_x, x):\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    return BCE\n","\n","\n","\n","# TODO\n","# 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n","# https://github.com/AntixK/PyTorch-VAE\n","class MultiVAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-VAE.\n","\n","    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiVAE, self).__init__()\n","        # init 부분은 Multi DAE 와 동일\n","        self.p_dims = p_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        else:\n","            self.q_dims = p_dims[::-1]\n","\n","        # Last dimension of q- network is for mean and variance\n","        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n","        # encoder 용 : q_layers는 p_dims 뒤집고 마지막항 한번더 연산추가한 Linear layer 들의 결합\n","        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n","        # decoder 용 : p_layer는 p_dims 그대로 사용한 Linear layer 들의 결합으로\n","        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n","        \n","        self.drop = nn.Dropout(dropout)\n","        self.init_weights()\n","    \n","    # 인풋 -> 인코더 ->  파라미터 재정비 -> 디코더 -> 아웃풋 + 인코더 결과물(mu, logvar)\n","    def forward(self, input):\n","        mu, logvar = self.encode(input)\n","        z = self.reparameterize(mu, logvar)\n","        h = self.decode(z)\n","        return h, mu, logvar\n","    \n","    def encode(self, input):\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","        #인코더에서는 MultiDAE 처럼 linear layer 돌림\n","        for i, layer in enumerate(self.q_layers):\n","            h = layer(h)\n","            if i != len(self.q_layers) - 1:\n","                h = F.tanh(h)\n","            else:\n","                # mu : 평균\n","                # logvar : log 분산 (표준편차가 음수가 되지 않기 위한 연산)\n","                # 처음 값들은 평균(mu)로 보내고 나머지 값들은 분산으로 보냄\n","                # h 는 [항목수, linear 로 변환된 dim]\n","                mu = h[:, :self.q_dims[-1]]\n","                logvar = h[:, self.q_dims[-1]:]\n","                # 이후 reparameterize 에서 연산처리함\n","        return mu, logvar\n","\n","    # training 과정에서 역전파를 수행할 수 있도록 재매개변수화 함수를 따로 생성했다고 함.\n","    def reparameterize(self, mu, logvar):\n","        # 학습중일 때는 평균 중심으로 분산 흩뿌려서 제출\n","        if self.training:\n","            #logvar로 표준편차 계산\n","            std = torch.exp(0.5 * logvar)\n","            # std를 정규분포 값으로 초기화한 eps\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        # 아닐 때는 그냥 평균값 배출\n","        else:\n","            return mu\n","\n","    def decode(self, z):\n","        h = z\n","        for i, layer in enumerate(self.p_layers):\n","            h = layer(h)\n","            if i != len(self.p_layers) - 1:\n","                h = F.tanh(h)\n","        return h\n","\n","    def init_weights(self):\n","        for layer in self.q_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","        \n","        for layer in self.p_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","\n","def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n","    # Loss function은 BCE와 KLD 사용\n","    # KL annealing 을 통해 Regularization 부여\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n","    # anneal 값을 0에서부터 특정 값까지 선형적으로 증가시켜 \n","    # 학습 초기에 reconstruction term을 강조하여 보다 효율적인 학습 도모함.\n","    return BCE + anneal * KLD\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nEfVTktbxa8"},"outputs":[],"source":["# 단순하게 torch.FloatTensor 쓰는 함수\n","def naive_sparse2tensor(data):\n","    return torch.FloatTensor(data.toarray())\n","\n","# 위 함수를 변형한 함수 (속도 개선)\n","# 근데 조교님 정답에선 이거 안씀\n","# 어떻게 쓰는 건지 모르겠음\n","def sparse2torch_sparse(data):\n","    \"\"\"\n","    scipy 행렬에서 torch 희소행렬로 L2 Norm을 이용하여 변환\n","    이렇게 하면 단순하게 torch.FloatTensor(data.toarray())를 쓰는 것 보다 빨라짐\n","    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n","    \"\"\"\n","    samples = data.shape[0]\n","    features = data.shape[1]\n","    # coo행렬은 coordinate format을 이용하여 희소행렬을 표현하는 방법\n","    # 원소의 좌표와 data 를 함께 넘겨줌\n","    # 참고 https://radish-greens.tistory.com/1\n","    coo_data = data.tocoo()\n","    indices = torch.LongTensor([coo_data.row, coo_data.col])\n","    row_norms_inv = 1 / np.sqrt(data.sum(1))\n","    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n","    values = np.array([row2val[r] for r in coo_data.row])\n","    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n","    return t\n","\n","\n","def train(model, criterion, optimizer, is_VAE = False):\n","    # Turn on training mode\n","    model.train()\n","    train_loss = 0.0\n","    start_time = time.time()\n","    global update_count\n","    # idxlist, N 는 아래 코드에서 따온 변수임\n","        # train_data = loader.load_data('train')\n","        # N = train_data.shape[0] : train data의 크기\n","        # idxlist = list(range(N)) : train data 크기만큼 range list\n","    \n","    # idxlist 를 랜덤으로 섞는다\n","    np.random.shuffle(idxlist)\n","    \n","    # 배치 단위로 잘라서 학습\n","    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n","        # 끝부분 처리\n","        end_idx = min(start_idx + args.batch_size, N)\n","        # 랜덤으로 섞인 train_data 배치사이즈로 자르기\n","        data = train_data[idxlist[start_idx:end_idx]]\n","        # 텐서로 변환\n","        data = naive_sparse2tensor(data).to(device)\n","        optimizer.zero_grad()# 모든 매개변수의 변화도 버퍼를 0으로 만듦\n","\n","        # Multi-VAE\n","        if is_VAE:\n","            #Default = 200000\n","            if args.total_anneal_steps > 0:\n","                anneal = min(args.anneal_cap, \n","                                1. * update_count / args.total_anneal_steps)\n","            else:\n","                anneal = args.anneal_cap # default = 0.2\n","\n","            # TODO\n","            # model에 입력 출력 코드를 작성해주세요\n","            recon_batch, mu, logvar = model(data)\n","\n","            # loss 함수를 설정해주세요        \n","            # criterion 은 loss_function_vae 가 들어옴\n","            loss = criterion(recon_batch, data, mu, logvar, anneal)\n","\n","        #Multi-DAE는 else로 처리\n","        else:\n","          recon_batch = model(data)\n","          loss = criterion(recon_batch, data)\n","\n","        loss.backward()             # 역전파\n","        train_loss += loss.item()   # loss 값 적립\n","        optimizer.step()            # 업데이트 진행\n","\n","        update_count += 1\n","\n","        # 100 번(Log_interval) 마다 실행\n","        # 근데 배치가 51개로 설정되어 있어서 10으로 바꿔 쓰면 그제야 실행됨\n","        if batch_idx % args.log_interval == 0 and batch_idx > 0: # log_interval : default=100\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n","                    'loss {:4.2f}'.format(\n","                        epoch, \n","                        batch_idx, len(range(0, N, args.batch_size)),\n","                        elapsed * 1000 / args.log_interval,\n","                        train_loss / args.log_interval))\n","            \n","\n","            start_time = time.time()\n","            train_loss = 0.0\n","\n","\n","def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n","    # Turn on evaluation mode\n","    model.eval()\n","    total_loss = 0.0\n","    global update_count\n","    \n","    # 테스트 리스트\n","    e_idxlist = list(range(data_tr.shape[0]))\n","    e_N = data_tr.shape[0]\n","    n100_list = []\n","    r20_list = []\n","    r50_list = []\n","    \n","    # 학습 아닐때 no_grad 써주기\n","    with torch.no_grad():\n","        # 배치 크기로 자르기\n","        for start_idx in range(0, e_N, args.batch_size):\n","            # 배치 끝처리\n","            end_idx = min(start_idx + args.batch_size, N)\n","            # 테스트의 트레인 데이터 자르기\n","            data = data_tr[e_idxlist[start_idx:end_idx]]\n","            # 테스트의 테스트 데이터 불러오기\n","            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n","\n","            data_tensor = naive_sparse2tensor(data).to(device)\n","            \n","            # Multi-VAE\n","            if is_VAE :\n","                if args.total_anneal_steps > 0:\n","                    anneal = min(args.anneal_cap, \n","                                    1. * update_count / args.total_anneal_steps)\n","                else:\n","                    anneal = args.anneal_cap\n","                \n","                #TODO\n","                #model에 입력 출력 코드를 작성해주세요\n","                recon_batch, mu, logvar = model(data_tensor)\n","                #loss 함수를 설정해주세요\n","                loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n","\n","            # Multi-DAE\n","            else :\n","                recon_batch = model(data_tensor)\n","                loss = criterion(recon_batch, data_tensor)\n","\n","\n","            total_loss += loss.item()\n","\n","            # Exclude examples from training set\n","            # 모델일 때는 cpu(), 텐서일 때는 cuda()로 쓴다고 함\n","            recon_batch = recon_batch.cpu().numpy()\n","            # data.nonzero() -> 배치단위로 잘린 데이터중 0이 아닌 값의 Index 값\n","            # 테스트의 트레인 데이터 값들을 마이너스 무한대로 변환\n","            recon_batch[data.nonzero()] = -np.inf\n","\n","            # 평가 (METRIC)\n","            # 100개의 배치로 계산한 NDCG\n","            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 10)\n","            # 20개 배치로 계산한 Recall@K\n","            r20 = Recall_at_k_batch(recon_batch, heldout_data, 2)\n","            # 50개 배치로 계산한 Recall@K\n","            r50 = Recall_at_k_batch(recon_batch, heldout_data, 5)\n","\n","            n100_list.append(n100)\n","            r20_list.append(r20)\n","            r50_list.append(r50)\n","    # loss 배치 단위로 평균내기\n","    total_loss /= len(range(0, e_N, args.batch_size))\n","    n100_list = np.concatenate(n100_list)\n","    r20_list = np.concatenate(r20_list)\n","    r50_list = np.concatenate(r50_list)\n","\n","    return total_loss, np.mean(n100_list), np.mean(r20_list), np.mean(r50_list)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JOsCJbb_X9gl"},"source":["### Metric 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxNtit6vbxa-"},"outputs":[],"source":["import bottleneck as bn\n","import numpy as np\n","\n","def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n","    '''\n","    Normalized Discounted Cumulative Gain@k for binary relevance\n","    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n","    '''\n","    # 마이너스 무한대 값이 들어있는 X_pred, 테스트 데이터가 들어있는 heldout_batch\n","    batch_users = X_pred.shape[0]\n","    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n","    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n","                       idx_topk_part[:, :k]]\n","    idx_part = np.argsort(-topk_part, axis=1)\n","\n","    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n","\n","    tp = 1. / np.log2(np.arange(2, k + 2))\n","\n","    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n","                         idx_topk].toarray() * tp).sum(axis=1)\n","    IDCG = np.array([(tp[:min(n, k)]).sum()\n","                     for n in heldout_batch.getnnz(axis=1)])\n","    return DCG / IDCG\n","\n","\n","def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n","    batch_users = X_pred.shape[0]\n","\n","    idx = bn.argpartition(-X_pred, k, axis=1)\n","    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n","    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n","\n","    X_true_binary = (heldout_batch > 0).toarray()\n","    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n","        np.float32)\n","    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n","    return recall"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cDD7lD7sHcnH"},"source":["## MultiDAE 테스트"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLYyTwToX4fm"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","model = MultiDAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n","criterion = loss_function_dae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50098,"status":"ok","timestamp":1647318176188,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"6rOEDs2Lbxa-","outputId":"6fb9eb56-26a4-45aa-d867-84dacf7b1e0a"},"outputs":[],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=False)\n","    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if n100 > best_n100:\n","        with open(\"MultiDAE.pt\", 'wb') as f:\n","            torch.save(model, f)\n","        best_n100 = n100\n","\n","\n","\n","# # Load the best saved model.\n","# with open(args.save, 'rb') as f:\n","#     model = torch.load(f)\n","\n","# # Run on test data.\n","# test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n","# print('=' * 89)\n","# print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n","#         'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n","# print('=' * 89)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"MultiDAE.pt\", 'wb') as f:\n","    torch.save(model, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict(model, data_tr, is_VAE=False):\n","    model.eval()\n","    global update_count\n","    users = []\n","    items = []\n","    with torch.no_grad():\n","        for start_idx in range(data_tr.shape[0]):\n","            data = data_tr[start_idx]\n","            data_tensor = naive_sparse2tensor(data).to(device)            \n","            # Multi-VAE\n","            if is_VAE :        \n","                recon_batch, mu, logvar = model(data_tensor)\n","            # Multi-DAE\n","            else:\n","                recon_batch = model(data_tensor)\n","            recon_batch = recon_batch.cpu().numpy()\n","            recon_batch[data.nonzero()] = -np.inf\n","            \n","            for rec in recon_batch:\n","                up = np.argpartition(rec, -10)[-10:].tolist()\n","                users.extend([start_idx] * 10)\n","                items.extend(up)\n","    user2rec_list = pd.DataFrame({'user': users, 'item': items}, dtype=int)\n","    return user2rec_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sub_data = loader.load_data('sub')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"MultiDAE.pt\", 'rb') as f:\n","    model = torch.load(f)    \n","sub_data = loader.load_data('sub')\n","user2rec_list = predict(model, sub_data, is_VAE=False)\n","user2rec_list['user'] = user2rec_list['user'].map(id2user)\n","user2rec_list['item'] = user2rec_list['item'].map(id2item)\n","Multi_DAE = user2rec_list.sort_values(by=['user','item'])\n","Multi_DAE"]},{"cell_type":"markdown","metadata":{"id":"o1QjCbMBXw4v"},"source":["## MultiVAE 테스트 (TODO)\n","\n","- 위의 MultiVAE 모델 코드, train, evaluate 함수를 완성하여, 아래 훈련 코드가 정상적으로 동작하도록 해보세요!\n","- 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n","  - https://github.com/AntixK/PyTorch-VAE\n","- 완성해야할 함수\n","  - MultiVAE class\n","    - forward\n","    - encode\n","    - decode\n","  - train\n","  - evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4941,"status":"ok","timestamp":1646922488386,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"78zFFNzgbxa_","outputId":"2d6d4723-d2db-4edc-b11b-a64b9ea95943"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","model = MultiVAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n","criterion = loss_function_vae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":7,"status":"error","timestamp":1646922488389,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"WoUFwndCvvtp","outputId":"4e50e9d7-8317-4d4f-8449-d384176378b8"},"outputs":[],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=True)\n","    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if n100 > best_n100:\n","        with open(\"MultiVAE.pt\", 'wb') as f:\n","            torch.save(model, f)\n","        best_n100 = n100\n","\n","\n","\n","# # Load the best saved model.\n","# with open(\"MultiVAE.pt\", 'rb') as f:\n","#     model = torch.load(f)\n","\n","# # Run on test data.\n","# test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n","# print('=' * 89)\n","# print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n","#         'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n","# print('=' * 89)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"MultiVAE.pt\", 'wb') as f:\n","    torch.save(model, f)"]},{"cell_type":"markdown","metadata":{"id":"yc8QsKFkJdHL"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"MultiVAE.pt\", 'rb') as f:\n","    model = torch.load(f)\n","sub_data = loader.load_data('sub')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["user2rec_list = predict(model, sub_data[22], is_VAE=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["user2rec_list['user'] = user2rec_list['user'].map(id2user)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["user2rec_list['item'] = user2rec_list['item'].map(id2item)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(list(id2user.items()), columns=['1', '2']).to_csv(\"id2user.csv\", index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(list(id2item.items()), columns=['1', '2']).to_csv(\"id2item.csv\", index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}
